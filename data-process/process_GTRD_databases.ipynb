{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a script for downloading and processing GTRD databases with ChIP-seq data for different organisms \n",
    "\n",
    "#### &copy; Wanwan Ge, 2018-05-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, load python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import yaml\n",
    "import requests   # download files from url\n",
    "import gzip\n",
    "import shutil\n",
    "import subprocess # run bash in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, define functions\n",
    "#### a) Split raw downloaded meta file into .bed files for each TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split mata file into .bed file for every individuel TF\n",
    "def split_meta_table_to_bed(ifile, hm_dir):\n",
    "    \n",
    "    odir = os.path.join(hm_dir, 'bed_from_metacluster/')\n",
    "    if not os.path.exists(odir):\n",
    "        os.makedirs(odir)\n",
    "\n",
    "    meta_file = pd.read_csv(ifile, header=0, sep='\\t')\n",
    "\n",
    "    grouped = meta_file.groupby(meta_file['tfTitle'])\n",
    "\n",
    "    for name, group in grouped:\n",
    "        TFname = name.split(' (')[0]\n",
    "        TFname = TFname.split(' [')[0]\n",
    "        TFname = TFname.replace('&#945;', '-alpha')\n",
    "        TFname = TFname.replace('&#946;', '-beta')\n",
    "        TFname = TFname.replace('&#947;', '-gamma')\n",
    "        TFname = TFname.replace('&#948;', '-delta')\n",
    "        TFname = TFname.replace('&#949;', '-epsilon')\n",
    "        TFname = TFname.replace('&#954;', '-kappa')\n",
    "        TFname = TFname.replace('/', '_')\n",
    "        TFname = TFname.replace(' ', '-')\n",
    "        TFname = TFname.replace('--', '-')\n",
    "        ofile = os.path.join(odir, TFname+'.bed')\n",
    "        group.to_csv( ofile, header=True, index=None, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Modify .bed files so that only max. 5000 sequences of length 200nt will be chosen, after sorting by ranking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sequences from the summit with a window size of 201 nt around the summit\n",
    "# rerank the peaks by peak count before extracting\n",
    "# extract maximum 5000 sequences\n",
    "def extract_bed_from_bed(indir, hm_dir, summit=100, maxN=5000):\n",
    "    \n",
    "    odir_bed = os.path.join(hm_dir, 'bed_summit100/')\n",
    "    odir_meta = os.path.join(hm_dir, 'meta_individual/')\n",
    "    \n",
    "    if not os.path.exists(odir_bed):\n",
    "        os.makedirs(odir_bed)\n",
    "\n",
    "    if not os.path.exists(odir_meta):\n",
    "        os.makedirs(odir_meta)\n",
    "\n",
    "    for i, filename in enumerate( sorted( glob.glob( os.path.join(indir +'*.bed')) ), start=1 ):\n",
    "        filename = os.path.basename(filename)\n",
    "        basename = os.path.splitext(filename)[0]\n",
    "        table = pd.read_csv(os.path.join(indir+filename), header=0, sep='\\t').values\n",
    "        seqname = table[:,0]\n",
    "        chromstart = table[:,1]\n",
    "        peak = table[:,3]\n",
    "        qVal = table[:,12] # peak.count\n",
    "        seqstart = chromstart + peak - summit\n",
    "        seqend = chromstart + peak + summit\n",
    "        # note: how to deal with seqstart < 0?\n",
    "        \n",
    "        qVal_sorted = qVal.argsort() # rerank sequences due to peak counts\n",
    "        \n",
    "        seqname = seqname[qVal_sorted[::-1]]\n",
    "        seqstart = seqstart[qVal_sorted[::-1]]\n",
    "        seqend = seqend[qVal_sorted[::-1]]\n",
    "        qVal = qVal[qVal_sorted[::-1]]\n",
    "        opath = os.path.join(odir_bed, basename + '_summits'+str(summit)+'.bed')\n",
    "        ofile = open(opath, \"w\")\n",
    "        length = min(maxN, len(seqname))\n",
    "        ofile.write('#CHROM\\tSTART\\tEND\\tqVal\\n')\n",
    "        for i in range(length):\n",
    "            ofile.write(seqname[i]+'\\t'+str(seqstart[i])+'\\t'+str(seqend[i])+'\\t'+str(qVal[i])+'\\n')\n",
    "        ofile.close()\n",
    "        \n",
    "        # generate meta_file for each individual dataset\n",
    "        opath_meta = os.path.join(odir_meta, basename + '.meta')\n",
    "        ofile_meta = open(opath_meta, \"w\")\n",
    "        ofile_meta.write('target_name\\ttfClassId.uniprotId\\ttfTitle\\tcell_set\\ttreatment_set\\texp_set\\n')\n",
    "        ofile_meta.write(basename+'\\t'\n",
    "                         +str(table[:,4][0])+'\\t'\n",
    "                         +str(table[:,5][0])+'\\t'\n",
    "                         +str(table[:,6][0])+'\\t'\n",
    "                         +str(table[:,7][0])+'\\t'\n",
    "                         +str(table[:,8][0])+'\\n')\n",
    "        ofile_meta.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Generate motifs.yaml from original meta file for summarizing motif information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate motifs.yaml from meta file\n",
    "def create_yaml_from_meta_bed(idir_meta, db_dir, species):\n",
    "    count = 0\n",
    "    items = []\n",
    "    ofile_yaml = db_dir+'/motifs.yaml'\n",
    "    for path2file in glob.glob(idir_meta+'/*'):\n",
    "        count += 1\n",
    "        TF = os.path.basename(path2file).split('.meta')[0]\n",
    "        file = pd.read_csv( path2file, sep='\\t', header=0 )\n",
    "        item = {\n",
    "            'filename': TF,\n",
    "            'target_name': TF,\n",
    "            'motif_id': 'GTRD_'+species+'_v101_'+str(count).zfill(4),\n",
    "            'pos_seq_file': 'source/sequences/'+TF+'.fasta',\n",
    "            'motif_init_file': 'source/initPWMs/'+TF+'.meme',\n",
    "            'TF_class_id': file['tfClassId.uniprotId'][0],\n",
    "            'TF_title': file['tfTitle'][0],\n",
    "            'cell_type': file['cell_set'][0]\n",
    "        }\n",
    "        items.append(item)\n",
    "\n",
    "    total = {\n",
    "        'models': items\n",
    "    }\n",
    "\n",
    "    ofile = open(ofile_yaml, 'w')\n",
    "\n",
    "    ofile.write( yaml.dump(total, default_flow_style=False) )\n",
    "\n",
    "    ofile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) generate YAML files for each database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yamls_for_DB(opath_db, species, fullname):\n",
    "    # 1. generate database_config.yaml\n",
    "    ofile_config = opath_db+'/database_config.yaml'\n",
    "    with open(ofile_config, \"w\") as fh:\n",
    "        print(\"version: 1.0.1\", file=fh)\n",
    "        print(\"display_name: GTRD-\"+species.upper(), file=fh)\n",
    "        print(\"organism: \"+fullname, file=fh)\n",
    "\n",
    "    # 2. generate model_specifications.yaml\n",
    "    ofile_spec = opath_db+'/model_specifications.yaml'\n",
    "    with open(ofile_spec, \"w\") as fh:\n",
    "        print(\"model_specification: \", file=fh)\n",
    "        print(\"  param_id: \", file=fh)\n",
    "        print(\"  data_source: GTRD\", file=fh)\n",
    "        print(\"  species: \"+fullname, file=fh)\n",
    "        print(\"  experiment: ChIPseq\", file=fh)\n",
    "        print(\"  motif_init_file_format: fasta\", file=fh)\n",
    "        print(\"  reversecomp: True\", file=fh)\n",
    "        print(\"  modelorder: 4\", file=fh)\n",
    "        print(\"  extend_1: 0\", file=fh)\n",
    "        print(\"  extend_2: 0\", file=fh)\n",
    "        print(\"  bgmodelorder: 2\", file=fh)\n",
    "        print(\"  em: True\", file=fh)\n",
    "        print(\"  fdr: True\", file=fh)\n",
    "        print(\"  mfold: 1\", file=fh)\n",
    "        print(\"  samplingorder: 2\", file=fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) download meta cluster file from GTRD url, given species name and home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_metacluster(url, species, hm_dir, species):\n",
    "    \n",
    "    ofile_meta = os.path.join(hm_dir, species+'_meta_clusters.interval')\n",
    "    \n",
    "    # download meta clusters from the url\n",
    "    ofile_gz = ofile_meta+'.gz'\n",
    "    response = requests.get(url)\n",
    "    with open(ofile_gz, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # unzip file\n",
    "    with gzip.open(ofile_gz, 'rb') as f_in:\n",
    "        with open(ofile_meta, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) create empty folders for hosting initial source and optimized models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_folders(db_dir):\n",
    "    # create empty folders\n",
    "    odir_source = os.path.join(db_dir, 'source')\n",
    "    odir_models = os.path.join(db_dir, 'models')\n",
    "    if not os.path.exists(odir_source):\n",
    "        os.mkdir(odir_source)\n",
    "    if not os.path.exists(odir_models):\n",
    "        os.mkdir(odir_models)\n",
    "    odir_seqs = os.path.join(odir_source, 'sequences')\n",
    "    odir_pwms = os.path.join(odir_source, 'initPWMs')\n",
    "    if not os.path.exists(odir_seqs):\n",
    "        os.mkdir(odir_seqs)\n",
    "    if not os.path.exists(odir_pwms):\n",
    "        os.mkdir(odir_pwms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "### Here is an example of processing human database\n",
    "#### 1) Define pathes and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrd_dir = '/home/wanwan/benchmark/GTRD/'\n",
    "serverdir = '/home/wanwan/workspace/webserver/motif_db/'\n",
    "\n",
    "species = 'human'\n",
    "fullname = 'Homo sapiens'\n",
    "url = 'http://gtrd.biouml.org/downloads/18.01/human_meta_clusters.interval.gz'\n",
    "\n",
    "hm_dir = gtrd_dir + species\n",
    "if not os.path.exists(hm_dir):\n",
    "    os.mkdir(hm_dir)\n",
    "db_dir = os.path.join(serverdir, 'GTRD_v1804_'+species.upper())\n",
    "if not os.path.exists(db_dir):\n",
    "    os.mkdir(db_dir)\n",
    "    \n",
    "meta_dir_filtered = os.path.join(hm_dir, 'meta_individual_filtered/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) download meta clusters from GTRD website: http://gtrd.biouml.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_metacluster(url, species, hm_dir, species) # This takes a while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) split meta clusters into bed files for each TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanwan/anaconda3/envs/sci35/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2827: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "split_meta_table_to_bed(ofile_meta, hm_dir) # This takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bed file to another bed file with window size of 201 from the summit\n",
    "extract_bed_from_bed(original_bed_dir, hm_dir, meta_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: in order to extract .fasta file of sequences from the bed file, you need to download the reference genomes\n",
    "##### http://hgdownload.soe.ucsc.edu/downloads.html\n",
    "\n",
    "#### 4) download reference genome for this species locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Extract FASTA file from BED file using bedtools\n",
    "###### Run it in shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dir=/home/wanwan/benchmark/GTRD/yeast\n",
    "mkdir -p ${dir}/fasta_summit100\n",
    "# make sure there is one and only one reference genome file (.fa) in the dir\n",
    "for file in ${dir}/bed_summit100/*.bed\n",
    "do \n",
    "    bedfile=$(basename ${file})\n",
    "    TFname=${bedfile%_summits100.*}\n",
    "    bedtools getfasta -fi ${dir}/*.fa -bed ${file} -fo ${dir}/fasta_summit100/${TFname}.fasta\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Run PEnGmotif and BaMMmotif for discovering and optimizating motifs\n",
    "##### Here is an example for running it locally.\n",
    "##### Note: it is better to run it on the cluster. Please copy the FASTA folder and the corresponding bash script to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DIR=/home/wanwan/benchmark/GTRD/yeast\n",
    "FASTA_DIR=${DIR}/fasta_summit100\n",
    "peng_dir=${DIR}/initPWMs\n",
    "bamm_dir=${DIR}/models\n",
    "mkdir -p ${peng_dir}\n",
    "mkdir -p ${bamm_dir}\n",
    "for file in ${FASTA_DIR}/*.fasta\n",
    "do\n",
    "    fastafile=$(basename ${file})\n",
    "    bn=${fastafile%.fasta}\n",
    "    shoot_peng.py -o ${peng_dir}/${bn}.meme -d ${peng_dir}/${bn}_tmp -w 8 ${FASTA_DIR}/${bn}.fasta > ${peng_dir}/${bn}.shootpeng.logg\n",
    "    rm -fr ${peng_dir}/${bn}_tmp\n",
    "    BaMMmotif ${bamm_dir}/${bn} ${FASTA_DIR}/${bn}.fasta --PWMFile ${peng_dir}/${bn}.meme --maxPWM 3 --EM -k 4 -q 0.3 --FDR -m 1 --scoreSeqset --extend 2 2 > ${bamm_dir}/${bn}.bamm.logg\n",
    "    plotPvalStats.R ${bamm_dir}/${bn}/ ${bn} --plots 1\n",
    "    plotMotifDistribution.R ${bamm_dir}/${bn}/ ${bn}\n",
    "    plotBaMMLogo.R ${bamm_dir}/${bn}/ ${bn} 0 --web 1\n",
    "    plotBaMMLogo.R ${bamm_dir}/${bn}/ ${bn} 1\n",
    "    plotBaMMLogo.R ${bamm_dir}/${bn}/ ${bn} 2 \n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Create empty folders for hosting the initial source and optimized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_db_folders(db_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Copying optimized motifs from cluster to local\n",
    "#### 9) Filtering step: filter the collection of meta files according to the actural TFs with motifs discovered. \n",
    "This is due to the reason that some TFs have too few sequences to search for motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "meta_dir=/home/wanwan/benchmark/GTRD/human/meta_individual\n",
    "meta_filter_dir=/home/wanwan/benchmark/GTRD/human/meta_individual_filtered\n",
    "mkdir -p ${meta_filter_dir}\n",
    "peng_dir=/home/wanwan/workspace/webserver/motif_db/GTRD_v1804_HUMAN/source/initPWMs\n",
    "for file in ${peng_dir}/*.meme\n",
    "do\n",
    "    memefile=$(basename ${file})\n",
    "    bn=${memefile%.meme}\n",
    "    cp -r ${meta_dir}/${bn}.meta ${meta_filter_dir}/\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Create motifs.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml_from_meta_bed(meta_dir_filtered, db_dir, species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) Create two other YAML files for the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yamls_for_DB(db_dir, species, fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12) Zipping all the files for each individual TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# zip files; -j flag is important for ignoring the path\n",
    "dir=/home/wanwan/workspace/webserver/motif_db/GTRD_v1804_HUMAN\n",
    "peng_dir=${dir}/source/initPWMs\n",
    "model_dir=${dir}/models\n",
    "for file in ${peng_dir}/*.meme\n",
    "do\n",
    "    memefile=$(basename ${file})\n",
    "    bn=${memefile%.meme}\n",
    "    zip -j ${model_dir}/${bn}/${bn}_complete.zip ${model_dir}/${bn}/*\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13) Last step: zip the whole database folder for uploading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the same steps for other databases\n",
    "\n",
    "### Additional information:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'mouse'\n",
    "fullname = 'Mus musculus'\n",
    "url = 'http://gtrd.biouml.org/downloads/18.01/mouse_meta_clusters.interval.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For yeast database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "species='yeast'\n",
    "fullname='Schizosaccharomyces pombe'\n",
    "url='http://gtrd.biouml.org/downloads/18.06alpha/Schizosaccharomyces_pombe_meta_clusters.interval.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### etc..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sci35]",
   "language": "python",
   "name": "conda-env-sci35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
